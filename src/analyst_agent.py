from huggingface_hub import InferenceClient
from src.config import HF_TOKEN, MODEL_ID, CLOUD_THRESHOLD

class AnalystAgent:
    """
    An AI-driven analyst that evaluates satellite imagery metadata 
    to determine if it meets specific environmental monitoring standards.
    """

    def __init__(self):
        """Initialises the inference client using the Hugging Face token."""
        self.client = InferenceClient(token=HF_TOKEN)

    def analyse_image_data(self, date, clouds, url):
        """
        Submits image metadata to the LLM for a quality assessment.

        Args:
            date (str): The date the image was captured.
            clouds (float): Percentage of cloud cover in the image.
            url (str): Link to the visual asset.

        Returns:
            str: The reasoning and decision generated by the AI agent.
        """
        prompt = (
            f"You are a Satellite Data Analyst specializing in rainforest conservation.\n"
            f"Task: Determine if this image is clear enough for analysis.\n"
            f"Threshold: Reject any image with more than {CLOUD_THRESHOLD}% cloud cover.\n\n"
            f"Data to Analyze:\n"
            f"- Capture Date: {date}\n"
            f"- Cloud Cover: {clouds}%\n"
            f"- Resource URL: {url}\n\n"
            f"Provide a concise report and state clearly if the image is accepted or rejected."
        )

        try:
            response = self.client.chat_completion(
                model=MODEL_ID,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=300,
                temperature=0.1
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"Analysis Error: The AI service could not be reached. Details: {e}"